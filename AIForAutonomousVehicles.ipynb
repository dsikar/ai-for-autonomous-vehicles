{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AiForAutonomousVehicles.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrEhWG7hQFz2"
      },
      "source": [
        "# AI for Autonomous Vehicles\n",
        "Brought to you by Daniel Sikar - daniel.sikar@city.ac.uk\n",
        "and\n",
        "City University of London Data Science Society - https://www.datasciencesociety.city/\n",
        "\n",
        "## Predicting steering angles from images using Convolutional Neural Networks\n",
        "\n",
        "Notebook: https://github.com/dsikar/ai-for-autonomous-vehicles/AIForAutonomousVehicles.ipynb\n",
        "\n",
        "## Learning objectives\n",
        "1. Gain familiarity with Google Colab and Jupyter Notebooks\n",
        "2. Load a pre-train model, make predictions and assess results\n",
        "3. Train a model to make predictions and assess results\n",
        "\n",
        "## Instructions\n",
        "Run each \"code\" cell sequencially from top to bottom, by clicking on each cell then click \"play\" button or keying Ctrl/Control + RETURN keys."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9XQxOCeThKF"
      },
      "source": [
        "# 1. Getting to know the environment\n",
        "A number of commented commands that can be run in a code cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoVotgTgTgbO"
      },
      "source": [
        "# How much space have we got?\n",
        "# !df -h\n",
        "# Command help\n",
        "# !man df\n",
        "# What is on the filesystem?\n",
        "!ls\n",
        "# Where are we?\n",
        "# !pwd\n",
        "# What does filesystem look like - / ?\n",
        "# !ls /\n",
        "# Downloading notebook:\n",
        "# File > \"Download .ipynb\"\n",
        "# or data on filesystem:\n",
        "# from google.colab import files\n",
        "# files.download('nlp-model.h5') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJAZEvYVVFP0"
      },
      "source": [
        "# 2. Get the data\n",
        "Download the the shared Google drive file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zP-6EIsQtif"
      },
      "source": [
        "# Install PyDrive\n",
        "!pip install PyDrive\n",
        "\n",
        "# Import modules\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Get the shareable link e.g. https://drive.google.com/file/d/1hDvGznkneVMVNNHAV98gIUuEW_tXC7z4/view?usp=sharing\n",
        "# Get the id from the link 1hDvGznkneVMVNNHAV98gIUuEW_tXC7z4\n",
        "downloaded = drive.CreateFile({'id':\"1hDvGznkneVMVNNHAV98gIUuEW_tXC7z4\"})   \n",
        "# For consistency, we use the same name as file uploaded to google drive\n",
        "downloaded.GetContentFile('ai-av-dataset.tar.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm2h1upH0XEO"
      },
      "source": [
        "# 3. Examine and decompress downloaded data\n",
        "Our dataset will be in \"dataset/testing/genTrackOneLap/logs_Wed_Nov_25_23_39_22_2020\" directory, while our pre-trained models in \"models\" directory.  \n",
        "The dataset was generated by [SDSandbox](https://github.com/tawnkramer/sdsandbox/), a [Unity](https://unity.com/) (game engine) based self-driving training and testing environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EXhdbR2ayNB"
      },
      "source": [
        "# !ls\n",
        "!tar xvf ai-av-dataset.tar.gz\n",
        "# !ls\n",
        "# !ls models\n",
        "# !ls dataset/testing/genTrackOneLap/logs_Wed_Nov_25_23_39_22_2020/*.jpg\n",
        "# !ls dataset/testing/genTrackOneLap/logs_Wed_Nov_25_23_39_22_2020/*.jpg | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVVcFQTblEtR"
      },
      "source": [
        "# 4. Examine one steering angle \"label\"\n",
        "Each image e.g. \"100_cam-image_array_.jpg\" will have a corresponding label e.g. \"record_100.json\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itmA3UvF0XER"
      },
      "source": [
        "# !ls dataset/testing/genTrackOneLap/logs_Wed_Nov_25_23_39_22_2020/100_cam-image_array_.jpg\n",
        "# !ls dataset/testing/genTrackOneLap/logs_Wed_Nov_25_23_39_22_2020/record_100.json\n",
        "!cat dataset/testing/genTrackOneLap/logs_Wed_Nov_25_23_39_22_2020/record_100.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp7goqrw0XES"
      },
      "source": [
        "# 5. Plot steering angles from testing dataset\n",
        "Go through all .json files, extracting the \"user/angle\" value, multiplying by 25 and plotting. Note, 25 is the maximum steering angle in this case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMzzIPk60XET"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "import seaborn as sns\n",
        "import os\n",
        "import fnmatch\n",
        "\n",
        "def GetJSONSteeringAngles(filemask):\n",
        "    \"\"\"\n",
        "    Get steering angles stored as 'user/angle' attributes in .json files\n",
        "    Inputs:\n",
        "        filemask: string, path and mask\n",
        "    Outputs\n",
        "        svals: list, steering values\n",
        "    \"\"\"\n",
        "    filemask = os.path.expanduser(filemask)\n",
        "    path, mask = os.path.split(filemask)\n",
        "\n",
        "    matches = []\n",
        "    for root, dirnames, filenames in os.walk(path):\n",
        "        for filename in fnmatch.filter(filenames, mask):\n",
        "            matches.append(os.path.join(root, filename))\n",
        "    # sort by create date\n",
        "    # matches = sorted(matches, key=os.path.getmtime)\n",
        "    # if create date lost, sort by string converted to number\n",
        "    matches = str2numsort(matches)\n",
        "    # steering values\n",
        "    svals = []\n",
        "    for fullpath in matches:\n",
        "            frame_number = os.path.basename(fullpath).split(\"_\")[0]\n",
        "            json_filename = os.path.join(os.path.dirname(fullpath), \"record_\" + frame_number + \".json\")\n",
        "            jobj = load_json(json_filename)\n",
        "            svals.append(jobj['user/angle'])\n",
        "    return svals\n",
        "\n",
        "def GetJPGFiles(filemask):\n",
        "    \"\"\"\n",
        "    Get list of .jpg files\n",
        "    Inputs:\n",
        "        filemask: string, path and mask\n",
        "    Outputs\n",
        "        matches: list, file paths\n",
        "    \"\"\"\n",
        "    filemask = os.path.expanduser(filemask)\n",
        "    path, mask = os.path.split(filemask)\n",
        "\n",
        "    matches = []\n",
        "    for root, dirnames, filenames in os.walk(path):\n",
        "        for filename in fnmatch.filter(filenames, mask):\n",
        "            matches.append(os.path.join(root, filename))\n",
        "    # sort by create date\n",
        "    # matches = sorted(matches, key=os.path.getmtime)\n",
        "    # if create date lost, sort by string converted to number\n",
        "    matches = str2numsort(matches)\n",
        "    return matches\n",
        "    \n",
        "def str2numsort(matches):\n",
        "    \"\"\"\n",
        "    Sort a known list of strings by number, this only works for 223_cam-image_array_.jpg.\n",
        "    Adjust the index in second .split() to adapt\n",
        "    Inputs\n",
        "        matches: list of strings, path to file\n",
        "    Outputs\n",
        "        matches: list of sorted strings\n",
        "    Example\n",
        "    matches = str2numsort(matches)\n",
        "    \"\"\"\n",
        "    # init empty list\n",
        "    mymatches = []\n",
        "    for i in range (0,len(matches)):\n",
        "        # extra the integer part of file e.g. 223 from '223_cam-image_array_.jpg' \n",
        "        # and append together with filename matches[i] to new list mymatches\n",
        "        mymatches.append([matches[i], int(matches[i].split('/')[-1].split('_')[0])])\n",
        "    # sort by second list array element\n",
        "    mymatches = sorted(mymatches, key=lambda x: x[1]);\n",
        "    # clear unsorted list\n",
        "    matches = []\n",
        "    # repopulated with sorted strings only\n",
        "    for i in range (0,len(mymatches)):\n",
        "        # append filename only\n",
        "        matches.append(mymatches[i][0])\n",
        "    return matches\n",
        "\n",
        "def load_json(filepath):\n",
        "    \"\"\"\n",
        "    Load a json file\n",
        "    Inputs\n",
        "        filepath: string, path to file\n",
        "    Outputs\n",
        "        data: dictionary, json key, value pairs\n",
        "    Example\n",
        "    path = \"~/git/msc-data/unity/roboRacingLeague/log/logs_Sat_Nov_14_12_36_16_2020/record_11640.json\"\n",
        "    js = load_json(path)\n",
        "    \"\"\"\n",
        "    with open(filepath, \"rt\") as fp:\n",
        "        data = json.load(fp)\n",
        "    return data\n",
        "\n",
        "# plot ground truth steering angles for\n",
        "filemask = './dataset/testing/genTrackOneLap/logs_Wed_Nov_25_23_39_22_2020/*.jpg'\n",
        "g = GetJSONSteeringAngles(filemask)\n",
        "# print(type(g)) # list\n",
        "g = np.asarray(g)\n",
        "# print(type(g)) # <class 'numpy.ndarray'>\n",
        "plt.rcParams[\"figure.figsize\"] = (18,3)\n",
        "nc = 25 # norm. constant, maximum steering angle\n",
        "\n",
        "plt.plot(g*nc)\n",
        "# plt.plot(sarr[:,1]*25, label=\"simulator\")\n",
        "\n",
        "plt.ylabel('Steering angle')\n",
        "plt.xlabel('Frame number')    \n",
        "# Set a title of the current axes.\n",
        "mytitle = 'Ground truth steering for logs_Wed_Nov_25_23_39_22_2020 - One lap recorded from Generated Track in \"Auto Drive w Rec\" mode'\n",
        "plt.title(mytitle)\n",
        "plt.grid(axis='y')\n",
        "# set limit\n",
        "plt.xlim([-5,len(g)+5])\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MOaFI7TpKvJ"
      },
      "source": [
        "#6. What versions of Python, Tensorflow and Keras are being used by Google Colab?\n",
        "These are the programming language and libraries used for generating the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjDnR_Y6pSHG"
      },
      "source": [
        "import keras\n",
        "import tensorflow\n",
        "!python --version\n",
        "print(\"TensorFlow version:\", tensorflow.__version__)\n",
        "print(\"Keras version:\", keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsmYvKeWbPLe"
      },
      "source": [
        "# 7. Load a pre-trained model\n",
        "Here we load a pre-trained model, keeping in mind that input (image) geometries are different for each of the pre-trained models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av_KDyzR0XEX"
      },
      "source": [
        "# !ls models\n",
        "# 20201207192948_nvidia2.h5 - expected image size 200x66 pixels\n",
        "# 20201207091932_nvidia1.h5 - expected image size 160x120 pixels\n",
        "from keras.models import load_model\n",
        "model=load_model('./models/20201207091932_nvidia1.h5')\n",
        "model.compile(\"sgd\", \"mse\")\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6N1eDHwlAEQ"
      },
      "source": [
        "# 8. Show predicted steering angle, ground truth steering angle label and corresponding image "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQMG38EU0XEY"
      },
      "source": [
        "# 4. Display image and predict\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "fullpath = 'dataset/testing/genTrackOneLap/logs_Wed_Nov_25_23_39_22_2020/100_cam-image_array_.jpg'\n",
        "img_arr = cv2.imread(fullpath)\n",
        "img_arr = cv2.resize(img_arr, (160, 120), cv2.INTER_AREA)\n",
        "plt.imshow(img_arr)\n",
        "img_arr = img_arr.reshape((1,) + img_arr.shape)\n",
        "mypred = model.predict(img_arr)\n",
        "# Output is an array with two elements, steering angle and throttle\n",
        "print(mypred)\n",
        "# We multiply by 25 because the steering angles in .json files are divided by 25 (maximum steering angle)\n",
        "print(mypred[0][0]*25)\n",
        "# Steering angle\n",
        "!cat dataset/testing/genTrackOneLap/logs_Wed_Nov_25_23_39_22_2020/record_100.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoBj_ihXm443"
      },
      "source": [
        "#9. Load image pre-processing (Augmentation) library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxdfEsP3_f1H"
      },
      "source": [
        "# code from \n",
        "# https://github.com/naokishibuya/car-behavioral-cloning\n",
        "import cv2, os\n",
        "import numpy as np\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH =  120, 160\n",
        "IMAGE_HEIGHT_NET, IMAGE_WIDTH_NET =  120, 160\n",
        "CROP_TOP, CROP_BOTTOM = 60, -25\n",
        "\n",
        "def load_image(image_path):\n",
        "    \"\"\"\n",
        "    Load RGB images from a file\n",
        "    \"\"\"\n",
        "    return mpimg.imread(image_path)\n",
        "\n",
        "\n",
        "def crop(image):\n",
        "    \"\"\"\n",
        "    Crop the image (removing the sky at the top and the car front at the bottom)\n",
        "    \"\"\"\n",
        "    return image[CROP_TOP:CROP_BOTTOM, :, :] # remove the sky and the car front\n",
        "\n",
        "\n",
        "def resize_net(image):\n",
        "    \"\"\"\n",
        "    Resize the image to the input shape used by the network model\n",
        "    \"\"\"\n",
        "    return cv2.resize(image, (IMAGE_WIDTH_NET, IMAGE_HEIGHT_NET), cv2.INTER_AREA)\n",
        "\n",
        "def resize_orig(image):\n",
        "    \"\"\"\n",
        "    Resize the image to the original game engine output shape\n",
        "    \"\"\"\n",
        "    return cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), cv2.INTER_AREA)    \n",
        "\n",
        "\n",
        "def rgb2yuv(image):\n",
        "    \"\"\"\n",
        "    Convert the image from RGB to YUV (This is what the NVIDIA model does)\n",
        "    \"\"\"\n",
        "    return cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
        "\n",
        "\n",
        "def preprocess(image_path):\n",
        "    \"\"\"\n",
        "    Combine all preprocess functions into one\n",
        "    \"\"\"\n",
        "    image = load_image(image_path)\n",
        "    image = resize_orig(image)\n",
        "    image = crop(image)\n",
        "    image = resize_net(image)\n",
        "    image = rgb2yuv(image)\n",
        "    return image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsTNRqPenLpa"
      },
      "source": [
        "# 10. Show predicted steering angle, ground truth steering angle label and corresponding pre-processed image "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUYpeR5ADJBB"
      },
      "source": [
        "# 5. Display image and predict, with preprocessing\n",
        "fullpath = 'dataset/testing/genTrackOneLap/logs_Wed_Nov_25_23_39_22_2020/100_cam-image_array_.jpg'\n",
        "img_arr = cv2.imread(fullpath)\n",
        "img_arr = cv2.resize(img_arr, (160, 120), cv2.INTER_AREA)\n",
        "img_arr = preprocess(fullpath)\n",
        "plt.imshow(img_arr)\n",
        "img_arr = img_arr.reshape((1,) + img_arr.shape)\n",
        "mypred = model.predict(img_arr)\n",
        "print(mypred)\n",
        "print(mypred[0][0]*25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9672m1rCxPrY"
      },
      "source": [
        "#11. Run predictions with no image pre-processing for testing lap (logs_Wed_Nov_25_23_39_22_2020)\n",
        "Note: the model was trained with pre-processing, pre-processed images are expected to produce more accurate predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF4TgUN1ASFv"
      },
      "source": [
        "# from keras.models import load_model\n",
        "# model=load_model('ai-av-model.h5')\n",
        "# model.compile(\"sgd\", \"mse\")\n",
        "filemask = 'dataset/testing/*.jpg'\n",
        "files = GetJPGFiles(filemask)\n",
        "# predPreProc = []\n",
        "predNoPreProc = []\n",
        "for file in files:\n",
        "  fullpath = file\n",
        "  img_arr = cv2.imread(fullpath)\n",
        "  img_arr = cv2.resize(img_arr, (160, 120), cv2.INTER_AREA)\n",
        "  img_arr = img_arr.reshape((1,) + img_arr.shape)\n",
        "  mypred = model.predict(img_arr)\n",
        "  predNoPreProc.append(mypred[0][0]) # append steering angle only\n",
        "print('*** Predictions completed ***')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj2zFqWfxdJj"
      },
      "source": [
        "#12. Plot results\n",
        "Note plot does not follow ground truth plot, obtained in step 5. Most predictions are outside the maximum steering angle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdQ4AAg4IOAg"
      },
      "source": [
        "# plot\n",
        "pnp = np.asarray(predNoPreProc)\n",
        "# print(type(g)) # <class 'numpy.ndarray'>\n",
        "plt.rcParams[\"figure.figsize\"] = (18,3)\n",
        "nc = 25 # norm. constant, maximum steering angle\n",
        "\n",
        "plt.plot(pnp*nc)\n",
        "# plt.plot(sarr[:,1]*25, label=\"simulator\")\n",
        "\n",
        "plt.ylabel('Steering angle')\n",
        "plt.xlabel('Frame number')    \n",
        "# Set a title of the current axes.\n",
        "mytitle = 'Predicted steering angles for logs_Wed_Nov_25_23_39_22_2020'\n",
        "plt.title(mytitle)\n",
        "plt.grid(axis='y')\n",
        "# set limit\n",
        "plt.xlim([-5,len(pnp)+5])\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaaIiRQgxrfi"
      },
      "source": [
        "#13. Run predictions with image pre-processing for testing lap (logs_Wed_Nov_25_23_39_22_2020)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_YEMKdxF6ya"
      },
      "source": [
        "files = GetJPGFiles(filemask)\n",
        "predPreProc = []\n",
        "# predNoPreProc = []\n",
        "for file in files:\n",
        "  fullpath = file\n",
        "  img_arr = preprocess(fullpath)\n",
        "  img_arr = img_arr.reshape((1,) + img_arr.shape)\n",
        "  mypred = model.predict(img_arr)\n",
        "  predPreProc.append(mypred[0][0]) # append steering angle only\n",
        "print('*** Predictions with pre-processing completed ***')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bvd9NzBxzNk"
      },
      "source": [
        "#14. Plot results\n",
        "Note this plot does follow the general trend of ground truth plot, but is \"centered\" around a negative value, all values being outside the Unity maximum steering angle, hence the model is also unusable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL7AsfegIg-m"
      },
      "source": [
        "# plot\n",
        "ppr = np.asarray(predPreProc)\n",
        "# print(type(g)) # <class 'numpy.ndarray'>\n",
        "plt.rcParams[\"figure.figsize\"] = (18,3)\n",
        "nc = 25 # norm. constant, maximum steering angle\n",
        "\n",
        "plt.plot(ppr*nc)\n",
        "# plt.plot(sarr[:,1]*25, label=\"simulator\")\n",
        "\n",
        "plt.ylabel('Steering angle')\n",
        "plt.xlabel('Frame number')    \n",
        "# Set a title of the current axes.\n",
        "mytitle = 'Ground truth steering for logs_Wed_Nov_25_23_39_22_2020 - One lap recorded from Generated Track in \"Auto Drive w Rec\" mode'\n",
        "plt.title(mytitle)\n",
        "plt.grid(axis='y')\n",
        "# set limit\n",
        "plt.xlim([-5,len(ppr)+5])\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ7o874RGzUr"
      },
      "source": [
        "#15. Goodness-of-steer\n",
        "How well/badly is my algorithm driving?\n",
        "\n",
        "$ g_s(p,g) = \\frac{\\sum_{i=1}^N \\lvert p(i)-g(i) \\rvert }{N} \\times n_c $\n",
        "\n",
        "where $p,g$ are prediction and ground truth arrays,  $N$ is the number of predictions and $n_c$ is the normalisation constant, which in this case is the maximum steering angle for the SDSandbox simulated vehicle (+- 25 degrees). In plain english, $g_s$ is defined as the sum of the absolute value of the difference between prediction and ground truth values, divided by the number of predictions multiplied by a normalization constant, that is the steering error average over all predictions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUqeipmSG8lh"
      },
      "source": [
        "def gos(p, g, n):\n",
        "    \"\"\"\n",
        "    Calculate the goodness-of-steer between a prediction and a ground truth array.\n",
        "    Inputs\n",
        "        p: array of floats, steering angle prediction\n",
        "        g: array of floats, steering angle ground truth.\n",
        "        n: float, normalization constant\n",
        "    Output\n",
        "        gos: float, average of absolute difference between ground truth and prediction arrays\n",
        "    \"\"\"\n",
        "    # todo add type assertion\n",
        "    assert len(p) == len(g), \"Arrays must be of equal length\"\n",
        "    return sum(abs(p - g)) / len(p) * n\n",
        "\n",
        "fpnp = gos(pnp, g, 25)\n",
        "fppr = gos(ppr, g, 25)\n",
        "str_pnp = \"{:.2f}\".format(fpnp)\n",
        "str_ppr = \"{:.2f}\".format(fppr)\n",
        "print(\"gs, no pre-processing = \", str_pnp)\n",
        "print(\"gs, with pre-processing = \", str_ppr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqiROaPDWWuI"
      },
      "source": [
        "#16. Overlay plots for further analysis\n",
        "We overlay the 2 predictions plus ground truth for some visual analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IrvKTSbJcYc"
      },
      "source": [
        "def plotMultipleSteeringAngles(p1, p2, p3, n, save=False, track= \"Track Name\", mname=\"model.h5\", w=18, h=3):\n",
        "    \"\"\"\n",
        "    Plot multiple predicted steering angles\n",
        "    Inputs\n",
        "        p: list of tuples, steering angles and labels\n",
        "        n: integer, \n",
        "    \"\"\"\n",
        "    plt.rcParams[\"figure.figsize\"] = (18,3)\n",
        "\n",
        "    \n",
        "    plt.plot(p1*25)\n",
        "    plt.plot(p2*25)\n",
        "    plt.plot(p3*25)\n",
        "    # plt.plot(sarr[:,1]*25, label=\"simulator\")\n",
        "\n",
        "    plt.ylabel('Steering angle')\n",
        "    plt.xlabel('Frame number')    \n",
        "    # Set a title of the current axes.\n",
        "    mytitle = 'Ground truth and predicted steering angles: ' + str(track) + ' model ' + str(mname)\n",
        "    plt.title(mytitle)\n",
        "    # show a legend on the plot\n",
        "    plt.legend(['No pre-processing (gs = ' + str_pnp + ')', 'With pre-processing (gs = ' + str_ppr + ')', 'Ground Truth'])\n",
        "    # Display a figure.\n",
        "    # horizontal grid only\n",
        "    plt.grid(axis='y')\n",
        "    # set limit\n",
        "    plt.xlim([-5,len(p1)+5])\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.show() \n",
        "\n",
        "plotMultipleSteeringAngles(pnp, ppr, g, 25, save=False, track= \"Generated Track,\", mname=\"20201207091932_nvidia1.h5\", w=18, h=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cweQnXNpyTdp"
      },
      "source": [
        "Conclusion: something seems to have gone seriously wrong with the model imported into Colab.\n",
        "This could be due to different Tensorflow/Keras/Python or other libraries skewing predictions.\n",
        "Let's reset and try to train one model from scratch.\n",
        "#17. Train a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biO5aDWEWi9s"
      },
      "source": [
        "# code from\n",
        "# https://github.com/tawnkramer/sdsandbox\n",
        "\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import time\n",
        "import fnmatch\n",
        "import argparse\n",
        "import random\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input\n",
        "from tensorflow.keras.layers import Dense, Lambda, ELU\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.layers import Cropping2D\n",
        "from tensorflow.keras.optimizers import Adadelta, Adam\n",
        "\n",
        "def shuffle(samples):\n",
        "    '''\n",
        "    randomly mix a list and return a new list\n",
        "    '''\n",
        "    ret_arr = []\n",
        "    len_samples = len(samples)\n",
        "    while len_samples > 0:\n",
        "        iSample = random.randrange(0, len_samples)\n",
        "        ret_arr.append(samples[iSample])\n",
        "        del samples[iSample]\n",
        "        len_samples -= 1\n",
        "    return ret_arr\n",
        "\n",
        "def load_json(filename):\n",
        "    with open(filename, \"rt\") as fp:\n",
        "        data = json.load(fp)\n",
        "    return data\n",
        "\n",
        "def generator(samples, batch_size=64,):\n",
        "    '''\n",
        "    Rather than keep all data in memory, we will make a function that keeps\n",
        "    it's state and returns just the latest batch required via the yield command.\n",
        "    \n",
        "    As we load images, we can optionally augment them in some manner that doesn't\n",
        "    change their underlying meaning or features. This is a combination of\n",
        "    brightness, contrast, sharpness, and color PIL image filters applied with random\n",
        "    settings. Optionally a shadow image may be overlayed with some random rotation and\n",
        "    opacity.\n",
        "    We flip each image horizontally and supply it as a another sample with the steering\n",
        "    negated.\n",
        "    '''\n",
        "    num_samples = len(samples)\n",
        "    \n",
        "    while 1: # Loop forever so the generator never terminates\n",
        "        samples = shuffle(samples)\n",
        "        #divide batch_size in half, because we double each output by flipping image.\n",
        "        for offset in range(0, num_samples, batch_size):\n",
        "            batch_samples = samples[offset:offset+batch_size]\n",
        "            \n",
        "            images = []\n",
        "            controls = []\n",
        "            for fullpath in batch_samples:\n",
        "                try:\n",
        "                \n",
        "                    frame_number = os.path.basename(fullpath).split(\"_\")[0]\n",
        "                    json_filename = os.path.join(os.path.dirname(fullpath), \"record_\" + frame_number + \".json\")\n",
        "                    data = load_json(json_filename)\n",
        "                    steering = float(data[\"user/angle\"])\n",
        "                    throttle = float(data[\"user/throttle\"])\n",
        "                \n",
        "                    try:\n",
        "                        image = Image.open(fullpath)\n",
        "                    except:\n",
        "                        print('failed to open', fullpath)\n",
        "                        continue\n",
        "\n",
        "                    #PIL Image as a numpy array\n",
        "                    image = np.array(image, dtype=np.float32)\n",
        "\n",
        "                    images.append(image)\n",
        "                    \n",
        "                    if 2 == 2:\n",
        "                        controls.append([steering, throttle])\n",
        "                    elif 2 == 1:\n",
        "                        controls.append([steering])\n",
        "                    else:\n",
        "                        print(\"expected 1 or 2 outputs\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(e)\n",
        "                    print(\"we threw an exception on:\", fullpath)\n",
        "                    yield [], []\n",
        "\n",
        "\n",
        "            # final np array to submit to training\n",
        "            X_train = np.array(images)\n",
        "            y_train = np.array(controls)\n",
        "            yield X_train, y_train\n",
        "\n",
        "\n",
        "def get_files(filemask):\n",
        "    '''\n",
        "    use a filemask and search a path recursively for matches\n",
        "    '''\n",
        "    #matches = glob.glob(os.path.expanduser(filemask))\n",
        "    #return matches\n",
        "    filemask = os.path.expanduser(filemask)\n",
        "    path, mask = os.path.split(filemask)\n",
        "    \n",
        "    matches = []\n",
        "    for root, dirnames, filenames in os.walk(path):\n",
        "        for filename in fnmatch.filter(filenames, mask):\n",
        "            matches.append(os.path.join(root, filename))\n",
        "    return matches\n",
        "\n",
        "\n",
        "def train_test_split(lines, test_perc):\n",
        "    '''\n",
        "    split a list into two parts, percentage of test used to seperate\n",
        "    '''\n",
        "    train = []\n",
        "    test = []\n",
        "\n",
        "    for line in lines:\n",
        "        if random.uniform(0.0, 1.0) < test_perc:\n",
        "            test.append(line)\n",
        "        else:\n",
        "            train.append(line)\n",
        "\n",
        "    return train, test\n",
        "\n",
        "def make_generators(inputs, limit=None, batch_size=64):\n",
        "    '''\n",
        "    load the job spec from the csv and create some generator for training\n",
        "    '''\n",
        "    \n",
        "    #get the image/steering pairs from the csv files\n",
        "    lines = get_files(inputs)\n",
        "    print(\"found %d files\" % len(lines))\n",
        "\n",
        "    if limit is not None:\n",
        "        lines = lines[:limit]\n",
        "        print(\"limiting to %d files\" % len(lines))\n",
        "    \n",
        "    train_samples, validation_samples = train_test_split(lines, test_perc=0.2)\n",
        "\n",
        "    print(\"num train/val\", len(train_samples), len(validation_samples))\n",
        "    \n",
        "    # compile and train the model using the generator function\n",
        "    train_generator = generator(train_samples, batch_size=batch_size)\n",
        "    validation_generator = generator(validation_samples, batch_size=batch_size)\n",
        "    \n",
        "    n_train = len(train_samples)\n",
        "    n_val = len(validation_samples)\n",
        "    \n",
        "    return train_generator, validation_generator, n_train, n_val\n",
        "\n",
        "\n",
        "def go(model_name, epochs=50, inputs='./log/*.jpg'):\n",
        "\n",
        "    print('working on model', model_name)\n",
        "\n",
        "    '''\n",
        "    modify config.json to select the model to train.\n",
        "    '''\n",
        "    model = get_nvidia_model(2)\n",
        "\n",
        "    '''\n",
        "    display layer summary and weights info\n",
        "    '''\n",
        "    #models.show_model_summary(model)\n",
        "\n",
        "    callbacks = [\n",
        "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=6, verbose=0),\n",
        "        keras.callbacks.ModelCheckpoint(model_name, monitor='val_loss', save_best_only=True, verbose=0),\n",
        "    ]\n",
        "    \n",
        "    batch_size = 128\n",
        "\n",
        "\n",
        "    #Train on session images\n",
        "    train_generator, validation_generator, n_train, n_val = make_generators(inputs, limit=None, batch_size=batch_size)\n",
        "\n",
        "    if n_train == 0:\n",
        "        print('no training data found')\n",
        "        return\n",
        "\n",
        "    steps_per_epoch = n_train // batch_size\n",
        "    validation_steps = n_val // batch_size\n",
        "\n",
        "    print(\"steps_per_epoch\", steps_per_epoch, \"validation_steps\", validation_steps)\n",
        "\n",
        "    history = model.fit_generator(train_generator, \n",
        "        steps_per_epoch = steps_per_epoch,\n",
        "        validation_data = validation_generator,\n",
        "        validation_steps = validation_steps,\n",
        "        epochs=epochs,\n",
        "        verbose=1,\n",
        "        callbacks=callbacks)\n",
        "    \n",
        "    try:\n",
        "        if 1 == 1:\n",
        "            # summarize history for loss\n",
        "            plt.plot(history.history['loss'])\n",
        "            plt.plot(history.history['val_loss'])\n",
        "            plt.plot(history.history['acc'])\n",
        "            plt.plot(history.history['val_acc'])            \n",
        "            plt.title('model loss/acc')\n",
        "            plt.ylabel('loss/acc')\n",
        "            plt.xlabel('epoch')\n",
        "            plt.legend(['train loss', 'test loss', 'train acc', 'test acc'], loc='upper left')\n",
        "            # plt.savefig('loss.png')\n",
        "    except:\n",
        "        print(\"problems with loss graph\")\n",
        "\n",
        "    model.save('ai-av-model.h5')\n",
        "\n",
        "def get_nvidia_model(num_outputs):\n",
        "    '''\n",
        "    this model is inspired by the NVIDIA paper\n",
        "    https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf\n",
        "    Activation is RELU\n",
        "    '''\n",
        "    # row, col, ch = conf.row, conf.col, conf.ch\n",
        "    row, col, ch = 120, 160, 3\n",
        "    \n",
        "    drop = 0.1\n",
        "    \n",
        "    img_in = Input(shape=(row, col, ch), name='img_in')\n",
        "    x = img_in\n",
        "    #x = Cropping2D(cropping=((10,0), (0,0)))(x) #trim 10 pixels off top\n",
        "    #x = Lambda(lambda x: x/127.5 - 1.)(x) # normalize and re-center\n",
        "    x = Lambda(lambda x: x/255.0)(x)\n",
        "    x = Conv2D(24, (5,5), strides=(2,2), activation='relu', name=\"conv2d_1\")(x)\n",
        "    x = Dropout(drop)(x)\n",
        "    x = Conv2D(32, (5,5), strides=(2,2), activation='relu', name=\"conv2d_2\")(x)\n",
        "    x = Dropout(drop)(x)\n",
        "    x = Conv2D(64, (5,5), strides=(2,2), activation='relu', name=\"conv2d_3\")(x)\n",
        "    x = Dropout(drop)(x)\n",
        "    x = Conv2D(64, (3,3), strides=(1,1), activation='relu', name=\"conv2d_4\")(x)\n",
        "    x = Dropout(drop)(x)\n",
        "    x = Conv2D(64, (3,3), strides=(1,1), activation='relu', name=\"conv2d_5\")(x)\n",
        "    x = Dropout(drop)(x)\n",
        "    \n",
        "    x = Flatten(name='flattened')(x)\n",
        "    x = Dense(100, activation='relu')(x)\n",
        "    #x = Dropout(drop)(x)\n",
        "    x = Dense(50, activation='relu')(x)\n",
        "    #x = Dropout(drop)(x)\n",
        "\n",
        "    outputs = []\n",
        "    outputs.append(Dense(num_outputs, activation='linear', name='steering_throttle')(x))\n",
        "    \n",
        "        \n",
        "    model = Model(inputs=[img_in], outputs=outputs)\n",
        "    opt = Adam(lr=0.0001)\n",
        "    model.compile(optimizer=opt, loss=\"mse\", metrics=['acc'])\n",
        "    return model\n",
        "\n",
        "go(\"nvidia1\", epochs=10, inputs='./dataset/testing/*.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iogqIIVKM5W_"
      },
      "source": [
        "#18. Load trained model ai-av-model.h5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83uMut5om1KD"
      },
      "source": [
        "# !ls\n",
        "from keras.models import load_model\n",
        "model=load_model('ai-av-model.h5')\n",
        "model.compile(\"sgd\", \"mse\")\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCJIrzkkNDBO"
      },
      "source": [
        "#19. Predict (no pre-processing)\n",
        "In this case, since model ai-av-model.h5 was trained with no pre-processing, the expectation is this case will produce the more accurate results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6iOvX9aNGBq"
      },
      "source": [
        "filemask = 'dataset/testing/*.jpg'\n",
        "files = GetJPGFiles(filemask)\n",
        "predNoPreProc = []\n",
        "for file in files:\n",
        "  fullpath = file\n",
        "  img_arr = cv2.imread(fullpath)\n",
        "  img_arr = cv2.resize(img_arr, (160, 120), cv2.INTER_AREA)\n",
        "  img_arr = img_arr.reshape((1,) + img_arr.shape)\n",
        "  mypred = model.predict(img_arr)\n",
        "  predNoPreProc.append(mypred[0][0]) # append steering angle only\n",
        "print('*** Predictions completed ***')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDi6U4wkTHRF"
      },
      "source": [
        "#20. Plot results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTpCl-IoTKJ9"
      },
      "source": [
        "# plot\n",
        "pnp = np.asarray(predNoPreProc)\n",
        "# print(type(g)) # <class 'numpy.ndarray'>\n",
        "plt.rcParams[\"figure.figsize\"] = (18,3)\n",
        "nc = 25 # norm. constant, maximum steering angle\n",
        "\n",
        "plt.plot(pnp*nc)\n",
        "# plt.plot(sarr[:,1]*25, label=\"simulator\")\n",
        "\n",
        "plt.ylabel('Steering angle')\n",
        "plt.xlabel('Frame number')    \n",
        "# Set a title of the current axes.\n",
        "mytitle = 'Predicted steering angles by ai-av-model.h5 for logs_Wed_Nov_25_23_39_22_2020'\n",
        "plt.title(mytitle)\n",
        "plt.grid(axis='y')\n",
        "# set limit\n",
        "plt.xlim([-5,len(pnp)+5])\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3cehbwiUYyG"
      },
      "source": [
        "#21. Predict (with pre-processing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55wJVqQ0Ueay"
      },
      "source": [
        "files = GetJPGFiles(filemask)\n",
        "predPreProc = []\n",
        "for file in files:\n",
        "  fullpath = file\n",
        "  img_arr = preprocess(fullpath)\n",
        "  img_arr = img_arr.reshape((1,) + img_arr.shape)\n",
        "  mypred = model.predict(img_arr)\n",
        "  predPreProc.append(mypred[0][0]) # append steering angle only\n",
        "print('*** Predictions with pre-processing completed ***')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM_RwOf5U2SK"
      },
      "source": [
        "#22. Plot results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64rntUpYU21T"
      },
      "source": [
        "# plot\n",
        "ppr = np.asarray(predPreProc)\n",
        "# print(type(g)) # <class 'numpy.ndarray'>\n",
        "plt.rcParams[\"figure.figsize\"] = (18,3)\n",
        "nc = 25 # norm. constant, maximum steering angle\n",
        "\n",
        "plt.plot(ppr*nc)\n",
        "# plt.plot(sarr[:,1]*25, label=\"simulator\")\n",
        "\n",
        "plt.ylabel('Steering angle')\n",
        "plt.xlabel('Frame number')    \n",
        "# Set a title of the current axes.\n",
        "mytitle = 'Predicted steering angles by ai-av-model.h5 for logs_Wed_Nov_25_23_39_22_2020, with image pre-processing'\n",
        "plt.title(mytitle)\n",
        "plt.grid(axis='y')\n",
        "# set limit\n",
        "plt.xlim([-5,len(ppr)+5])\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRf8gkm9VOHV"
      },
      "source": [
        "#23. Goodness-of-steer for our Colab trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HTev7HuVVtw"
      },
      "source": [
        "fpnp = gos(pnp, g, 25)\n",
        "fppr = gos(ppr, g, 25)\n",
        "str_pnp = \"{:.2f}\".format(fpnp)\n",
        "str_ppr = \"{:.2f}\".format(fppr)\n",
        "print(\"gs, no pre-processing = \", str_pnp)\n",
        "print(\"gs, with pre-processing = \", str_ppr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rod1J_E2W61n"
      },
      "source": [
        "#24. Overlay plots for further analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnZezvCGW8el"
      },
      "source": [
        "plotMultipleSteeringAngles(pnp, ppr, g, 25, save=False, track= \"Generated Track\", mname=\"ai-av-model.h5\", w=18, h=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z556O4llbtQu"
      },
      "source": [
        "\n",
        "#Recap\n",
        "* We used a pre-trained Tensorflow/Keras model and also trained a model to predict steering angles given a set of images (taken from a lap around a track generated by the Unity game engine, using the SDSandbox environment).\n",
        "* This is known as a \"regression\" task, where a continuous value (steering angle) is prediction, as opposed to \"classification\" tasks, we have tackled in previous workshops, where an image was classified as [fire/no-fire](https://github.com/CityDataScienceSociety/ComputerVisionWorkshops/tree/main/detect-fire-with-AI), or and audio file was classified as the words [yes or no](https://github.com/CityDataScienceSociety/NLP-Workshop).\n",
        "* The same image size used for training must be used at \"inference\" time, for predicting.\n",
        "* The model could be deployed onto the [DIY Robocars](https://diyrobocars.com/) model scale platform, if trained with the appropriate track dataset (e.g. Warehouse).\n",
        "# Thanks for taking part! :)\n",
        "\n"
      ]
    }
  ]
}